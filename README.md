Iowa Housing Price Prediction üè°This project involves building a machine learning model to predict residential home prices in Ames, Iowa. Developed as part of the Kaggle "Learn Intro to Machine Learning" course, it demonstrates the transition from basic data exploration to advanced ensemble modeling using Random Forests.üìã Project OverviewThe goal is to predict the SalePrice of a house based on its physical characteristics. The project covers:Data Loading & Exploration: Using Pandas to handle CSV data.Feature Selection: Identifying key variables that influence housing prices.Model Validation: Using Mean Absolute Error (MAE) to measure prediction accuracy.Optimization: Balancing underfitting and overfitting by tuning tree depth.üìä Dataset & FeaturesThe model uses the Ames Housing Dataset. The following features were selected for the final $X$ matrix:LotArea: Total lot size in square feet.YearBuilt: Original construction date.1stFlrSF & 2ndFlrSF: First and second-floor square footage.FullBath: Number of full bathrooms.BedroomAbvGr: Number of bedrooms above grade.TotRmsAbvGrd: Total rooms above grade (excluding bathrooms).ü§ñ Models ImplementedDecision Tree Regressor: Initially used to establish a baseline and understand the impact of max_leaf_nodes on error rates.Random Forest Regressor: A more robust ensemble model that averages predictions from multiple trees to reduce variance and improve MAE.üìà PerformanceValidation Method: train_test_split with random_state=1.Primary Metric: Mean Absolute Error (MAE).Result: The Random Forest model significantly outperformed the single Decision Tree, providing more generalized predictions for unseen data.üõ†Ô∏è Technologies UsedLanguage: Python 3.xLibraries: Pandas, Scikit-learnEnvironment: Kaggle NotebooksHow to use this projectEnsure you have pandas and scikit-learn installed.Clone this repository.Download the train.csv and test.csv from the Kaggle Housing Prices Competition.Run the notebook cells to generate the submission.csv file.
